# -*- coding: utf-8 -*-
"""Machine Learning -- DATA 301 Project -- Abbey Towse & Jack Rhines.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1drWxzzRCiocqY-dszl6DahYobmbmTZMa

# **Machine Learning**

# Upload CSV and Important Packages
"""

import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')

df_football = pd.read_csv('/content/drive/MyDrive/football.csv')
df_football = df_football.drop(columns="Unnamed: 0")
df_football.head()

df_2022 = df_football[df_football["year"] == 2022]
df_football = df_football[df_football["year"] != 2022]

"""# Model Selection

## Function to calculate F1 Score for each Model

We looked at the models based on F1 Score, Precision, and Recall and decided that the F1 Score was the best metric to use.
"""

def get_f1_scores(features):

  # define training set
  X_train = df_football[features]
  y_train = df_football["superbowl"]

  pipeline = make_pipeline(
      KNeighborsClassifier(n_neighbors=3)
  )

  f1_scores = cross_val_score(pipeline, X_train, y_train, cv=10, scoring="f1_macro")
  #precision = cross_val_score(pipeline, X_train, y_train, cv=10, scoring="precision_macro")
  #recall = cross_val_score(pipeline, X_train, y_train, cv=10, scoring="recall_macro")
  return f1_scores.mean()

"""Various models to try to find best f1 score"""

f1scores = pd.Series()

for features in [
    ["W-L%"],
    ["W-L%", "SRS"],
    ["W-L%", "SRS", "seed"],
    ["W-L%", "head_coach_exp_yrs"],
    ["W-L%", "SRS", "head_coach_exp_yrs"],
    ["W-L%", "head_coach_exp_yrs", "draft_order"],
    ["W-L%", "head_coach_exp_yrs", "draft_order", "seed"],
    ["W-L%", "SRS", "head_coach_exp_yrs", "draft_order", "seed"],
    ["W-L%", "SoS", "SRS", "head_coach_exp_yrs", "draft_order", "seed"],
    ["W-L%", "MoV", "SRS", "head_coach_exp_yrs", "draft_order", "seed"],
    ["W-L%", "seed"],
    ["W-L%", "MoV", "SoS"],
    ["W-L%", "MoV", "SoS", "SRS"],
    ["W-L%", "MoV", "SoS", "SRS", "OSRS", "DSRS"],
    ["W-L%", "MoV", "SoS", "PD"],
    ["W-L%", "MoV", "SoS", "PD", "PF", "PA"],
    ["W-L%", "MoV", "SoS", "SRS", "PD"],
    ["W-L%", "MoV", "SoS", "SRS", "OSRS", "DSRS", "PD", "PF", "PA"],
    ["W-L%", "MoV", "SoS", "draft_order"],
    ["W-L%", "MoV", "SoS", "head_coach_exp_yrs"],
    ["W-L%", "MoV", "SoS", "seed"],
    ["W-L%", "MoV", "SoS", "draft_order", "head_coach_exp_yrs"],
    ["W-L%", "MoV", "SoS", "SRS", "draft_order", "head_coach_exp_yrs"],
    ["W-L%", "MoV", "SoS", "draft_order", "head_coach_exp_yrs", "seed"],
    ["W-L%", "MoV", "SoS", "SRS", "draft_order", "head_coach_exp_yrs", "seed"],
    ["W-L%", "MoV", "SoS", "SRS", "PD", "draft_order", "head_coach_exp_yrs", "seed"],
    ["W-L%", "MoV", "SoS", "SRS", "OSRS", "DSRS", "PD", "PF", "PA", "draft_order", "head_coach_exp_yrs", "seed"]]:
      f1scores[str(features)] = get_f1_scores(features)

f1scores, f1scores.idxmax()

"""Based on these F1 scores we see that ['W-L%', 'SRS', 'head_coach_exp_yrs', 'draft_order', 'seed'] are the best variables to use for our model

Fit a pipeline for our best model
"""

X_train = df_football[['W-L%', 'SRS', 'head_coach_exp_yrs', 'draft_order', 'seed']]
y_train = df_football["superbowl"]

pipeline = make_pipeline(
    KNeighborsClassifier(n_neighbors=3)
)

pipeline.fit(X_train, y=y_train)

"""## GridSearch Cross Validation to determine best value of k"""

from sklearn.model_selection import GridSearchCV

grid_search = GridSearchCV(
    pipeline,
    param_grid={"kneighborsclassifier__n_neighbors": range(1, 50)},
    scoring="f1_macro",
    cv=10
)

grid_search.fit(X_train, y_train)
pd.DataFrame(grid_search.cv_results_).sort_values("rank_test_score")
grid_search.best_params_

"""Our GridSearch determine the best value of k is k=3

# See our models predictions for teams in every year

Make a base data frame with just the year 2002

Here we lower the classification threshold from 50% to 10% because it is rare and improbable to win the Superbowl
"""

df_2002 = df_football[df_football["year"] == 2002]
features = ['W-L%', 'SRS', 'head_coach_exp_yrs', 'draft_order', 'seed']

df_prob = pd.DataFrame()

for i in range(len(df_2002)):
  x_predict = []

  for feature in features:
    x_predict.append(df_2002.iloc[i][feature])
  probas_ = pipeline.predict_proba([x_predict])
  if (probas_[:, 1] > .1) == True:
    entry = { 'Team': df_2002.iloc[i]["Tm"], 'Year': 2002, 'Probability': probas_[0][1]}
    df_prob = df_prob.append(entry, ignore_index=True)

"""Loop through all the years to add them to the base data frame"""

features = ['W-L%', 'SRS', 'head_coach_exp_yrs', 'draft_order', 'seed']
df_prob = pd.DataFrame()

for year in range(2002, 2022):
  df_year = df_football[df_football["year"] == year]

  for i in range(len(df_2002)):
    x_predict = []

    for feature in features:
      x_predict.append(df_year.iloc[i][feature])

    probas_ = pipeline.predict_proba([x_predict])

    if (probas_[:, 1] > .1) == True:
      entry = { 'Team': df_year.iloc[i]["Tm"],
               'Year': year,
               'Probability': probas_[0][1],
               'Actually Won': df_football[(df_football["Tm"] == df_year.iloc[i]["Tm"]) & (df_football["year"] == year)].iloc[0]["superbowl"],
               'Made Playoffs': df_football[(df_football["Tm"] == df_year.iloc[i]["Tm"]) & (df_football["year"] == year)].iloc[0]["made_playoffs"]}
      df_prob = df_prob.append(entry, ignore_index=True)

"""Fix data types and see the data frame with all the teams with at least a 10% chance of winning"""

df_prob["Year"] = df_prob["Year"].astype(int)
df_prob["Actually Won"] = df_prob["Actually Won"].astype(int)
df_prob["Made Playoffs"] = df_prob["Made Playoffs"].astype(int)
df_prob

"""Verify that the team that won the Superbowl every year was in fact predicted by our model"""

df_prob[df_prob["Actually Won"] == 1]

"""Make a plot showing what teams our model predicted and who actually won that season"""

colors = df_prob["Actually Won"].map({
    0: "black",
    1: "red"
})

df_prob.plot.scatter(
    x="Year",
    y="Team",
    color=colors,
    title = "Predicted Super Bowl Winners"
)

# We can see in this plot that our model does predict that all of the actual super bowl winners had a chance.

"""# Make a prediction on who will win the 2022 season Superbowl
Based on the 2022 season thus far
"""

features = ['W-L%', 'SRS', 'head_coach_exp_yrs', 'draft_order', 'seed']

df_prob_2022 = pd.DataFrame()

for i in range(len(df_2022)):
  x_predict = []

  for feature in features:
    x_predict.append(df_2022.iloc[i][feature])

  probas_ = pipeline.predict_proba([x_predict])
  if (probas_[:, 1] > .1) == True:
    entry = { 'Team': df_2022.iloc[i]["Tm"], 'Year': 2022, 'Probability': probas_[0][1]}
    df_prob_2022 = df_prob_2022.append(entry, ignore_index=True)

"""Our model predicts the winner of the 2022 Superbowl will be the Buffalo Bills or the San Francisco 49ers"""

df_prob_2022
